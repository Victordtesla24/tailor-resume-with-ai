"""Type stub file for data_collection module."""

from datetime import datetime
from typing import Any, Dict, List, Optional, Set

class PIIData:
    names: Set[str]
    emails: Set[str]
    phones: Set[str]
    locations: Set[str]
    organizations: Set[str]
    dates: Set[str]
    def __init__(self) -> None: ...

class PIIDetector:
    def __init__(self) -> None: ...
    def detect(self, text: str) -> PIIData: ...

class Tokenizer:
    def __init__(self) -> None: ...
    def replace_pii(self, text: str, pii: PIIData) -> str: ...

class ErrorTracker:
    def __init__(self, api_key: Optional[str] = None) -> None: ...
    def track_error(self, error_key: str, error_message: str) -> Optional[str]: ...

class RateLimiter:
    def __init__(self, max_requests: int, window_seconds: int) -> None: ...
    def can_access(self) -> bool: ...

class DataCollector:
    def __init__(self, storage_path: str) -> None: ...
    def save_training_data(
        self,
        resume_text: str,
        job_description: str,
        tailored_output: str,
        extra_metadata: Dict[str, Any],
    ) -> None: ...

class DataRetentionManager:
    def __init__(self, storage_path: str) -> None: ...
    def cleanup_old_data(self, days: int) -> None: ...

class TextProcessor:
    def __init__(self) -> None: ...
    def extract_sentences(self, text: str) -> List[str]: ...
    def tokenize_text(self, text: str) -> List[str]: ...
    def remove_stopwords(self, tokens: List[str]) -> List[str]: ...
    def lemmatize_tokens(self, tokens: List[str]) -> List[str]: ...
    def process_text(self, text: str) -> List[str]: ...
    def extract_entities(self, text: str) -> Dict[str, Set[str]]: ...
